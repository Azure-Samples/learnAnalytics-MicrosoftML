[
["index.html", "Machine Learning with the MicrosoftML Package Chapter 1 Prerequisites 1.1 MicrosoftML References 1.2 Useful Resources", " Machine Learning with the MicrosoftML Package Ali Zaidi 2017-09-14 Chapter 1 Prerequisites This workshop covers the fundamentals of statistical machine learning with the MicrosoftML package. MicrosoftML is a package that works in tandem with the RevoScaleR package and Microsoft R Server. In order to use the MicrosoftML and RevoScaleR libraries, you need an installation of Microsoft R Server or Microsoft R Client. You can download Microsoft R Server through MSDN here: R Server for Linux R Server for Hadoop R Server for Windows R Server for SQL Server (In-Database) You can download Microsoft R Client through the following sources: R Client for Windows R Client for Linux R Client Docker Image 1.1 MicrosoftML References Cheat Sheet Overview of MicrosoftML Functions Function Reference Quickstarts MSDN Site for Microsoft R Server MSDN Site for Microsoft R Client R Client Overview 1.2 Useful Resources Introduction to Statistical Learning Video Lectures My favorite course on statistical learning Worth doing twice! Introduction to Statistical Learning Textbook Baby Statistical Learning Elements of Statistical Learning Textbook Papa Statistical Learning R for Data Science Covers the core tools in the tidyverse ecosystem for data science and analytics Microsoft R for Data Science My two-day workshop on Microsoft R Server for Data Science Microsoft R Server and Spark My 1.5 day course on Microsoft R Server and Spark Integration Scalable Data Science with Microsoft R Server and Spark In progress book on data science with Microsoft R Server and Spark "],
["exploratory-data-analysis-and-feature-engineering.html", "Chapter 2 Exploratory Data Analysis and Feature Engineering 2.1 Visualize Densities 2.2 Spatial Visualizations 2.3 Exercises", " Chapter 2 Exploratory Data Analysis and Feature Engineering Import your favorite libraries and set up your favorite plotting theme. library(tidyverse) theme_set(theme_minimal()) Now let’s import some data. Our data source is 1990-census level of housing in California. We’ll use easy the readr package to load in our data. You could equivalently use read.csv, or data.table::fread if you wanted incredible speed. We’ll later see how to use data sources using the RevoScaleR readers. Since we’re using readr, our data is a tbl. This means we will get some dplyr and tibble features, and it’ll behave a little differently than a traditional data.frame. housing &lt;- read_csv(&quot;data/housing.csv&quot;) class(housing) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; glimpse(housing) ## Observations: 20,640 ## Variables: 10 ## $ longitude &lt;dbl&gt; -122.23, -122.22, -122.24, -122.25, -122.25... ## $ latitude &lt;dbl&gt; 37.88, 37.86, 37.85, 37.85, 37.85, 37.85, 3... ## $ housing_median_age &lt;dbl&gt; 41, 21, 52, 52, 52, 52, 52, 52, 42, 52, 52,... ## $ total_rooms &lt;dbl&gt; 880, 7099, 1467, 1274, 1627, 919, 2535, 310... ## $ total_bedrooms &lt;dbl&gt; 129, 1106, 190, 235, 280, 213, 489, 687, 66... ## $ population &lt;dbl&gt; 322, 2401, 496, 558, 565, 413, 1094, 1157, ... ## $ households &lt;dbl&gt; 126, 1138, 177, 219, 259, 193, 514, 647, 59... ## $ median_income &lt;dbl&gt; 8.3252, 8.3014, 7.2574, 5.6431, 3.8462, 4.0... ## $ median_house_value &lt;dbl&gt; 452600, 358500, 352100, 341300, 342200, 269... ## $ ocean_proximity &lt;chr&gt; &quot;NEAR BAY&quot;, &quot;NEAR BAY&quot;, &quot;NEAR BAY&quot;, &quot;NEAR B... housing ## # A tibble: 20,640 x 10 ## longitude latitude housing_median_age total_rooms total_bedrooms ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -122.23 37.88 41 880 129 ## 2 -122.22 37.86 21 7099 1106 ## 3 -122.24 37.85 52 1467 190 ## 4 -122.25 37.85 52 1274 235 ## 5 -122.25 37.85 52 1627 280 ## 6 -122.25 37.85 52 919 213 ## 7 -122.25 37.84 52 2535 489 ## 8 -122.25 37.84 52 3104 687 ## 9 -122.26 37.84 42 2555 665 ## 10 -122.25 37.84 52 3549 707 ## # ... with 20,630 more rows, and 5 more variables: population &lt;dbl&gt;, ## # households &lt;dbl&gt;, median_income &lt;dbl&gt;, median_house_value &lt;dbl&gt;, ## # ocean_proximity &lt;chr&gt; 2.1 Visualize Densities Suppose we want to visualize the distribution of the numeric columns, such as housing_median_age. How would you visualize that density? housing %&gt;% keep(is_double) %&gt;% gather %&gt;% ggplot(aes(x = value)) + geom_histogram() + facet_wrap(~key, scales = &quot;free&quot;) ## Warning: Removed 207 rows containing non-finite values (stat_bin). 2.2 Spatial Visualizations The histograms of the longitude and latitude columns seem like they are in some reasonable range of data. Let’s visualize the locations. housing %&gt;% ggplot(aes(x = longitude, y = latitude)) + geom_point() Looks indeed like California! We can improve this chart in many ways. Let’s first add some transparency so we can get a better sense of the density of points: housing %&gt;% ggplot(aes(x = longitude, y = latitude)) + geom_point(alpha = 0.15) Nice, we can already see some dense clusters for higher population regions like the Bay Area, Sacramento and Los Angeles. Let’s add some additional attributes, like the population: housing %&gt;% ggplot(aes(x = longitude, y = latitude, size = population)) + geom_point(alpha = 0.15) And now let’s see if we can add a gradient fill for another numeric value, like the median housing price: housing %&gt;% ggplot(aes(x = longitude, y = latitude, size = population, colour = median_house_value)) + geom_point(alpha = 0.095) Interesting, we can definitely see the higher price ranges in LA and the Bay Area. Let’s see if we can change the colour scheme to get an even better visualization: housing %&gt;% ggplot(aes(x = longitude, y = latitude, size = population, colour = median_house_value)) + geom_point(alpha = 0.095) + scale_colour_gradient(low = &quot;yellow&quot;, high = &quot;red&quot;) If you want to plot the points on top of an actual polygon of the state map, you can do that using geom_map and using the map_data function in ggplot2. I find it a bit messy, but it might be worthwile if you are plotting various regions/states. While we’re at it, let’s put some final themes on our plot to make it more aesthetically pleasing. housing %&gt;% mutate(state = &quot;california&quot;) %&gt;% ggplot(aes(x = longitude, y = latitude, size = population, colour = median_house_value)) + geom_map(map = filter(map_data(&quot;state&quot;), region == &quot;california&quot;), aes(map_id = state), fill = &quot;lightgrey&quot;, colour = &quot;lightgrey&quot;) + geom_point(alpha = 0.1) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + scale_size_continuous(labels = scales::comma) + scale_colour_gradient(low = &quot;yellow&quot;, high = &quot;red&quot;, labels = scales::dollar) 2.3 Exercises How does proximity to the ocean effect median house values? Try to visualize housing prices the above using the ocean proximity variable as the colour/fill aesthetic and median_house_value as the size aesthetic. We saw that faceting could allow us to compare distributions rather easily. Try a facetted plot where you facet by quantiles of the median_income column. This will allow you to compare the distribution of housing values, populations/demographics across different income groups. The dplyr::mutate, stats::quntile, and ggplot2::facet_wrap functions should be useful here. "],
["regression-models.html", "Chapter 3 Regression Models 3.1 Splitting into Train and Test Sets 3.2 Training Regression Learners 3.3 Scoring Our Data on the Test Set 3.4 Training Many Models Concurrently 3.5 Exercise", " Chapter 3 Regression Models 3.1 Splitting into Train and Test Sets Let’s sample our data into train and test sets. In order to do this efficiently, we will use the RevoScaleR package. We’ll first create a RxXdfData object, which is a more efficient and scalable data structure than R data.frames. Their primary distinction is that they do not reside in memory, but on-disk. library(tidyverse) library(dplyrXdf) library(foreach) ## ## Attaching package: &#39;foreach&#39; ## The following objects are masked from &#39;package:purrr&#39;: ## ## accumulate, when library(doRSR) ## Loading required package: iterators library(MicrosoftML) theme_set(theme_minimal()) out_xdf &lt;- file.path( &quot;data&quot;, &quot;housing.xdf&quot;) housing_xdf &lt;- rxDataStep(inData = housing, outFile = out_xdf, maxRowsByCols = nrow(housing)*ncol(housing), rowsPerRead = 5000, overwrite = TRUE) housing_xdf %&lt;&gt;% factorise(ocean_proximity) %&gt;% persist(out_xdf, overwrite = TRUE) The RevoScaleR and MicrosoftML functions are primarily prefixed with rx. In this function below, we will use the rxSplit function to split our data into train and test sets. Observe that since our data is now on-disk, and compromises of multiple blocks, we have to use the .rxNumRows argument to inform the session how many rows are currently being processed in the current block: split_xdf &lt;- function(data) { splits &lt;- rxSplit(data, outFileSuffixes = c(&quot;Train&quot;, &quot;Test&quot;, &quot;Validate&quot;), splitByFactor = &quot;splitVar&quot;, overwrite = TRUE, transforms = list(splitVar = factor( sample(c(&quot;Train&quot;, &quot;Test&quot;, &quot;Validate&quot;), size = .rxNumRows, replace = TRUE, prob = c(0.65, 0.25, 0.1)), levels = c(&quot;Train&quot;, &quot;Test&quot;, &quot;Validate&quot;))), rngSeed = 123, consoleOutput = TRUE) return(splits) } splits &lt;- split_xdf(housing_xdf) names(splits) &lt;- c(&quot;train&quot;, &quot;test&quot;, &quot;validate&quot;) Now that we have our train and test sets, we can conduct begin to train our models. 3.2 Training Regression Learners Let’s train our first regression model. We can start with the a glm model. GLMs, short for generalized linear models, are a general class of linear algorithms. In this exercise, our goal is to predict the median housing value given the other variables. lin_mod &lt;- rxLinMod(median_house_value ~ housing_median_age + total_rooms + total_bedrooms + population + households + median_income + ocean_proximity, data = splits$train) That was pretty easy, but let’s generalize our approach so that we can estimate a variety of models quickly and efficiently. First, we’ll create a wrapper function to automatically create our model matrix for us dynamically from our data. make_form &lt;- function(xdf = housing_xdf, resp_var = &quot;median_house_value&quot;, vars_to_skip = c(&quot;splitVar&quot;, &quot;longitude&quot;, &quot;latitude&quot;)) { library(stringr) non_incl &lt;- paste(vars_to_skip, collapse = &quot;|&quot;) x_names &lt;- names(xdf) features &lt;- x_names[!str_detect(x_names, resp_var)] features &lt;- features[!str_detect(features, non_incl)] form &lt;- as.formula(paste(resp_var, paste0(features, collapse = &quot; + &quot;), sep = &quot; ~ &quot;)) return(form) } make_form(xdf = splits$train) ## median_house_value ~ housing_median_age + total_rooms + total_bedrooms + ## population + households + median_income + ocean_proximity ## &lt;environment: 0xadfcc10&gt; Now let’s create a modeling wrapper, which will take our dataset, a formula, and a model, and train it for us. estimate_model &lt;- function(xdf_data = splits$train, form = make_form(xdf = xdf_data), model = rxLogit, ...) { rx_model &lt;- model(form, data = xdf_data, ...) return(rx_model) } Now we can quickly iterate over our data and train models using different learning algorithms. For example, the above example suffers from the issue that we didn’t scale our data prior to learning. This can have an adverse effect on the optimization function of the learning algorithm, as it’ll favor the variables with more disperse scales. We’ll use the SDCA - Stochastic Dual Coordinate Ascent learning algorithm, which automatically applies a min-max scaling to our data prior to training. sdca &lt;- estimate_model(model = rxFastLinear, type = &quot;regression&quot;) ## Automatically adding a MinMax normalization transform, use &#39;norm=Warn&#39; or &#39;norm=No&#39; to turn this behavior off. ## Using 2 threads to train. ## Automatically choosing a check frequency of 2. ## Warning: Skipped 141 instances with missing features/label during training ## Auto-tuning parameters: maxIterations = 110. ## Auto-tuning parameters: L2 = 0.0001. ## Auto-tuning parameters: L1Threshold (L1/L2) = 0. ## Using best model from iteration 48. ## Not training a calibrator because it is not needed. ## Elapsed time: 00:00:01.6831767 ## Elapsed time: 00:00:00.0678240 summary(sdca) ## Call: ## model(formula = form, data = xdf_data, type = &quot;regression&quot;) ## ## SDCAR (RegressorTrainer) for: median_house_value~housing_median_age+total_rooms+total_bedrooms+population+households+median_income+ocean_proximity ## Data: xdf_data (RxXdfData Data Source) ## File name: /home/alizaidi/bookdown-demo/housing.splitVar.Train.xdf ## ## First 12 of 12 Non-zero Coefficients: ## (Bias): -221101.6 ## population: -893426.4 ## median_income: 539692.2 ## total_bedrooms: 338512.2 ## ocean_proximity.ISLAND: 324354.5 ## ocean_proximity.NEAR BAY: 288516.2 ## ocean_proximity.NEAR OCEAN: 285277.7 ## ocean_proximity.&lt;1H OCEAN: 271619.3 ## households: 251829.5 ## ocean_proximity.INLAND: 202295.3 ## total_rooms: -81016.05 ## housing_median_age: 32083.27 3.3 Scoring Our Data on the Test Set Now that we our model trained, we can score it on our test set. Let’s create a prediction XDF where we’ll save our results to. pred_xdf &lt;- file.path(&quot;/home&quot;, system(&quot;whoami&quot;, intern = TRUE), &quot;scored.xdf&quot;) if (file.exists(pred_xdf)) file.remove(pred_xdf) ## [1] TRUE scored_xdf &lt;- RxXdfData(pred_xdf) rxPredict(lin_mod, data = splits$test, outData = pred_xdf, writeModelVars = T, predVarNames = c(&quot;linmod&quot;), overwrite = T) rxGetInfo(pred_xdf) ## File name: /home/alizaidi/scored.xdf ## Number of observations: 5150 ## Number of variables: 9 ## Number of blocks: 5 ## Compression type: zlib rxLinePlot(linmod ~ median_house_value, data = pred_xdf, type = &quot;p&quot;) Let’s also score our SDCA model: rxPredict(sdca, data = splits$test, outData = pred_xdf, writeModelVars = T) ## Elapsed time: 00:00:00.2908180 # rxGetInfo(pred_xdf, numRows = 2) rxLinePlot(Score ~ median_house_value, data = pred_xdf, type = &quot;p&quot;) 3.4 Training Many Models Concurrently Let’s take our functions and train multiple models in parallel. We have already trained two linear models. Let’s add two ensemble tree algorithms to the mix, rxBTrees, and simultaneously train a random forest using rxDForest. To run them in parallel, we can use the foreach package with a local parallel backend. rxSetComputeContext(RxLocalParallel()) registerDoRSR(computeContext = rxGetComputeContext()) models &lt;- list(&quot;btrees&quot; = rxBTrees, &quot;forest&quot; = rxDForest) models &lt;- foreach(i = models) %dopar% estimate_model(model = i) names(models) &lt;- c(&quot;btrees&quot;, &quot;forest&quot;) models ## $btrees ## ## Call: ## model(formula = form, data = xdf_data) ## ## ## Loss function of boosted trees: bernoulli ## Number of boosting iterations: 10 ## No. of variables tried at each split: 2 ## ## OOB estimate of deviance: NA ## ## $forest ## ## Call: ## model(formula = form, data = xdf_data) ## ## ## Type of decision forest: anova ## Number of trees: 10 ## No. of variables tried at each split: 2 ## ## Mean of squared residuals: 4591841792 ## % Var explained: 65 lapply(models, summary) ## $btrees ## Length Class Mode ## ntree 1 -none- numeric ## mtry 1 -none- numeric ## type 1 -none- character ## forest 10 -none- list ## oob.err 4 data.frame list ## init.pred 1 -none- numeric ## params 65 -none- list ## formula 3 formula call ## call 3 -none- call ## ## $forest ## Length Class Mode ## ntree 1 -none- numeric ## mtry 1 -none- numeric ## type 1 -none- character ## forest 10 -none- list ## oob.err 4 data.frame list ## params 65 -none- list ## formula 3 formula call ## call 3 -none- call 3.5 Exercise Use the rxDTree function to sit a single regression tree to this dataset. Visualize the fit of your decision tree using the RevoTreeView library and it’s createTreeView and plot functions. "],
["classification-models-for-computer-vision.html", "Chapter 4 Classification Models for Computer Vision 4.1 Hand-Written Digit Classifiation 4.2 Visualizing Digits 4.3 Visualize Digits 4.4 Split the Data into Train and Test Sets 4.5 Exercises", " Chapter 4 Classification Models for Computer Vision 4.1 Hand-Written Digit Classifiation In this module, we will examine the MNIST dataset, which is a set of 70,000 images of digits handwritten by high school students and employees of the US Census Bureau. MNIST is considered the “hello-world” of the machine-learning world, and is often a good place to start for understanding classification algorithms. Let’s load the MNIST dataset. library(MicrosoftML) library(tidyverse) library(magrittr) ## ## Attaching package: &#39;magrittr&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## set_names ## The following object is masked from &#39;package:tidyr&#39;: ## ## extract library(dplyrXdf) theme_set(theme_minimal()) mnist_xdf &lt;- file.path(&quot;data&quot;, &quot;MNIST.xdf&quot;) mnist_xdf &lt;- RxXdfData(mnist_xdf) Let’s take a look at the data: rxGetInfo(mnist_xdf) ## File name: /home/alizaidi/bookdown-demo/data/MNIST.xdf ## Number of observations: 70000 ## Number of variables: 786 ## Number of blocks: 7 ## Compression type: zlib Our dataset contains 70K records, and 786 columns. There are actually 784 features, because each image in the dataset is a 28x28 pixel image. The two additional columns are for the label, and a column with a pre-sampled train and test split. 4.2 Visualizing Digits Let’s make some visualizations to examine the MNIST data and see what we can use for a classifier to classify the digits. mnist_df &lt;- rxDataStep(inData = mnist_xdf, outFile = NULL, maxRowsByCols = nrow(mnist_xdf)*ncol(mnist_xdf)) %&gt;% tbl_df Let’s see the average for each digit: mnist_df %&gt;% keep(is.numeric) %&gt;% rowMeans() %&gt;% data.frame(intensity = .) %&gt;% tbl_df %&gt;% bind_cols(mnist_df) %T&gt;% print -&gt; mnist_df ## # A tibble: 70,000 x 787 ## intensity Label V2 V3 V4 V5 V6 V7 V8 V9 V10 ## &lt;dbl&gt; &lt;fctr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 35.10842 5 0 0 0 0 0 0 0 0 0 ## 2 39.66199 0 0 0 0 0 0 0 0 0 0 ## 3 24.79974 4 0 0 0 0 0 0 0 0 0 ## 4 21.85587 1 0 0 0 0 0 0 0 0 0 ## 5 29.60969 9 0 0 0 0 0 0 0 0 0 ## 6 37.75638 2 0 0 0 0 0 0 0 0 0 ## 7 22.50765 1 0 0 0 0 0 0 0 0 0 ## 8 45.74872 3 0 0 0 0 0 0 0 0 0 ## 9 13.86990 1 0 0 0 0 0 0 0 0 0 ## 10 27.93878 4 0 0 0 0 0 0 0 0 0 ## # ... with 69,990 more rows, and 776 more variables: V11 &lt;int&gt;, V12 &lt;int&gt;, ## # V13 &lt;int&gt;, V14 &lt;int&gt;, V15 &lt;int&gt;, V16 &lt;int&gt;, V17 &lt;int&gt;, V18 &lt;int&gt;, ## # V19 &lt;int&gt;, V20 &lt;int&gt;, V21 &lt;int&gt;, V22 &lt;int&gt;, V23 &lt;int&gt;, V24 &lt;int&gt;, ## # V25 &lt;int&gt;, V26 &lt;int&gt;, V27 &lt;int&gt;, V28 &lt;int&gt;, V29 &lt;int&gt;, V30 &lt;int&gt;, ## # V31 &lt;int&gt;, V32 &lt;int&gt;, V33 &lt;int&gt;, V34 &lt;int&gt;, V35 &lt;int&gt;, V36 &lt;int&gt;, ## # V37 &lt;int&gt;, V38 &lt;int&gt;, V39 &lt;int&gt;, V40 &lt;int&gt;, V41 &lt;int&gt;, V42 &lt;int&gt;, ## # V43 &lt;int&gt;, V44 &lt;int&gt;, V45 &lt;int&gt;, V46 &lt;int&gt;, V47 &lt;int&gt;, V48 &lt;int&gt;, ## # V49 &lt;int&gt;, V50 &lt;int&gt;, V51 &lt;int&gt;, V52 &lt;int&gt;, V53 &lt;int&gt;, V54 &lt;int&gt;, ## # V55 &lt;int&gt;, V56 &lt;int&gt;, V57 &lt;int&gt;, V58 &lt;int&gt;, V59 &lt;int&gt;, V60 &lt;int&gt;, ## # V61 &lt;int&gt;, V62 &lt;int&gt;, V63 &lt;int&gt;, V64 &lt;int&gt;, V65 &lt;int&gt;, V66 &lt;int&gt;, ## # V67 &lt;int&gt;, V68 &lt;int&gt;, V69 &lt;int&gt;, V70 &lt;int&gt;, V71 &lt;int&gt;, V72 &lt;int&gt;, ## # V73 &lt;int&gt;, V74 &lt;int&gt;, V75 &lt;int&gt;, V76 &lt;int&gt;, V77 &lt;int&gt;, V78 &lt;int&gt;, ## # V79 &lt;int&gt;, V80 &lt;int&gt;, V81 &lt;int&gt;, V82 &lt;int&gt;, V83 &lt;int&gt;, V84 &lt;int&gt;, ## # V85 &lt;int&gt;, V86 &lt;int&gt;, V87 &lt;int&gt;, V88 &lt;int&gt;, V89 &lt;int&gt;, V90 &lt;int&gt;, ## # V91 &lt;int&gt;, V92 &lt;int&gt;, V93 &lt;int&gt;, V94 &lt;int&gt;, V95 &lt;int&gt;, V96 &lt;int&gt;, ## # V97 &lt;int&gt;, V98 &lt;int&gt;, V99 &lt;int&gt;, V100 &lt;int&gt;, V101 &lt;int&gt;, V102 &lt;int&gt;, ## # V103 &lt;int&gt;, V104 &lt;int&gt;, V105 &lt;int&gt;, V106 &lt;int&gt;, V107 &lt;int&gt;, ## # V108 &lt;int&gt;, V109 &lt;int&gt;, V110 &lt;int&gt;, ... Visualize average intensity by label: ggplot(mnist_df, aes(x = intensity, y = ..density..)) + geom_density(aes(fill = Label), alpha = 0.3) Let’s try a boxplot: ggplot(mnist_df, aes(x = Label, y = intensity)) + geom_boxplot(aes(fill = Label), alpha = 0.3) 4.3 Visualize Digits Let’s plot a sample set of digits: flip &lt;- function(matrix) { apply(matrix, 2, rev) } plot_digit &lt;- function(samp) { digit &lt;- unlist(samp) m &lt;- flip(matrix(rev(as.numeric(digit)), nrow = 28)) image(m, col = grey.colors(255)) } mnist_df[11, ] %&gt;% select(-Label, -intensity, -splitVar) %&gt;% sample_n(1) %&gt;% rowwise() %&gt;% plot_digit 4.4 Split the Data into Train and Test Sets splits &lt;- rxSplit(mnist_xdf, splitByFactor = &quot;splitVar&quot;, overwrite = TRUE) names(splits) &lt;- c(&quot;train&quot;, &quot;test&quot;) Let’s first train a softmax classifier using the rxLogisticRegression: softmax &lt;- estimate_model(xdf_data = splits$train, form = make_form(splits$train, resp_var = &quot;Label&quot;, vars_to_skip = c(&quot;splitVar&quot;)), model = rxLogisticRegression, type = &quot;multiClass&quot;) ## Automatically adding a MinMax normalization transform, use &#39;norm=Warn&#39; or &#39;norm=No&#39; to turn this behavior off. ## LBFGS multi-threading will attempt to load dataset into memory. In case of out-of-memory issues, turn off multi-threading by setting trainThreads to 1. ## Beginning optimization ## num vars: 7850 ## improvement criterion: Mean Improvement ## L1 regularization selected 3699 of 7850 weights. ## Not training a calibrator because it is not needed. ## Elapsed time: 00:00:18.6072601 ## Elapsed time: 00:00:00.0334469 Let’s see how we did. Let’s examine our results on the train set: softmax_scores &lt;- rxPredict(modelObject = softmax, data = splits$test, outData = tempfile(fileext = &quot;.xdf&quot;), overwrite = TRUE, extraVarsToWrite = &quot;Label&quot;) ## Elapsed time: 00:00:01.0520198 We can make a confusion matrix of all our results: rxCube( ~ Label : PredictedLabel , data = softmax_scores, returnDataFrame = TRUE) -&gt; softmax_scores_df softmax_scores_df %&gt;% ggplot(aes(x = Label, y = PredictedLabel, fill = Counts)) + geom_raster() + scale_fill_continuous(low = &quot;steelblue2&quot;, high = &quot;mediumblue&quot;) Here we are plotting the raw counts. This might unfairly represent the more populated classes. Let’s weight each count by the total number of samples in that class: label_rates &lt;- softmax_scores_df %&gt;% tbl_df %&gt;% group_by(Label) %&gt;% mutate(rate = Counts/sum(Counts)) label_rates %&gt;% ggplot(aes(x = Label, y = PredictedLabel, fill = rate)) + geom_raster() + scale_fill_continuous(low = &quot;steelblue2&quot;, high = &quot;mediumblue&quot;) Let’s fill out all the correct scores with zeros so we can see the errors more clearly: label_rates %&gt;% mutate(error_rate = ifelse(Label == PredictedLabel, 0, rate)) %&gt;% ggplot(aes(x = Label, y = PredictedLabel, fill = error_rate)) + geom_raster() + scale_fill_continuous(low = &quot;steelblue2&quot;, high = &quot;mediumblue&quot;, labels = scales::percent) 4.5 Exercises Take a look at David Robinson’s tweet on using a single pixel to distinguish between pairs of digits. You can find his gist saved in the Rscripts directory. "],
["convolutional-neural-networks-for-computer-vision.html", "Chapter 5 Convolutional Neural Networks for Computer Vision 5.1 LeNet-5 5.2 Model Metrics", " Chapter 5 Convolutional Neural Networks for Computer Vision In the previous section we conducted multi-class classification using a softmax regression algorithm. The most popular approach for image classification is now convolutional neural networks. This module describes how to use convolutional networks. MicrosoftML uses the Net# specification for defining neural network architectures. In the ../nnet directory, we have already created the specifications for you. Examine the architecture in “MNIST.nn”. In this network, we have two convolutional layers and one fully connected layer. library(tidyverse) library(MicrosoftML) theme_set(theme_minimal()) rxNeuralNetFile &lt;- file.path(&quot;nnet/MNIST.nn&quot;) nn &lt;- readChar(rxNeuralNetFile, file.info(rxNeuralNetFile)$size) nnet_fit &lt;- rxNeuralNet(make_form(splits$train, resp_var = &quot;Label&quot;, vars_to_skip = c(&quot;splitVar&quot;)), data = splits$train, type = &quot;multiClass&quot;, numIterations = 9, netDefinition = nn, initWtsDiameter = 1.0, normalize = &quot;No&quot;) ## Not adding a normalizer. ## Using: SSE Math ## Loading net from: ## ***** Net definition ***** ## const T = true; ## const F = false; ## input Picture [28, 28]; ## hidden Convolve1 [5, 12, 12] from Picture convolve { ## InputShape = [28, 28]; ## KernelShape = [5, 5]; ## Stride = [2, 2]; ## MapCount = 5; ## } ## hidden Convolve2 [50, 4, 4] from Convolve1 convolve { ## InputShape = [5, 12, 12]; ## KernelShape = [1, 5, 5]; ## Stride = [1, 2, 2]; ## Sharing = [F, T, T]; ## MapCount = 10; ## } ## hidden Full3 [100] from Convolve2 all; ## output Result [10] from Full3 all; ## ***** Reduced ***** ## const T = true; ## const F = false; ## input Picture [28, 28]; ## hidden Convolve1 [5, 12, 12] from Picture convolve { ## InputShape = [28, 28]; ## KernelShape = [5, 5]; ## Stride = [2, 2]; ## MapCount = 5; ## } ## hidden Convolve2 [50, 4, 4] from Convolve1 convolve { ## InputShape = [5, 12, 12]; ## KernelShape = [1, 5, 5]; ## Stride = [1, 2, 2]; ## Sharing = [false, true, true]; ## MapCount = 10; ## } ## hidden Full3 100 from Convolve2 all; ## output Result 10 from Full3 all; ## ***** End net definition ***** ## Input count: 784 ## Output count: 10 ## Output Function: SoftMax ## Loss Function: CrossEntropy ## PreTrainer: NoPreTrainer ## ___________________________________________________________________ ## Starting training... ## Learning rate: 0.001000 ## Momentum: 0.000000 ## InitWtsDiameter: 1.000000 ## ___________________________________________________________________ ## Initializing 3 Hidden Layers, 82540 Weights... ## Estimated Pre-training MeanError = 4.142561 ## Iter:1/9, MeanErr=1.582342(-61.80%), 610.87M WeightUpdates/sec ## Iter:2/9, MeanErr=0.651257(-58.84%), 615.72M WeightUpdates/sec ## Iter:3/9, MeanErr=0.474688(-27.11%), 626.65M WeightUpdates/sec ## Iter:4/9, MeanErr=0.390425(-17.75%), 627.81M WeightUpdates/sec ## Iter:5/9, MeanErr=0.344977(-11.64%), 620.60M WeightUpdates/sec ## Iter:6/9, MeanErr=0.314282(-8.90%), 613.83M WeightUpdates/sec ## Iter:7/9, MeanErr=0.290820(-7.47%), 611.50M WeightUpdates/sec ## Iter:8/9, MeanErr=0.273693(-5.89%), 616.90M WeightUpdates/sec ## Iter:9/9, MeanErr=0.256158(-6.41%), 631.15M WeightUpdates/sec ## Done! ## Estimated Post-training MeanError = 0.247149 ## ___________________________________________________________________ ## Not training a calibrator because it is not needed. ## Elapsed time: 00:01:24.7007751 As in the previous section with linear classifiers, we can create our confusion matrices: nnet_score &lt;- rxPredict(modelObject = nnet_fit, data = splits$test, outData = tempfile(fileext = &quot;.xdf&quot;), overwrite = TRUE, extraVarsToWrite = &quot;Label&quot;) ## Elapsed time: 00:00:01.5443943 Now that we have our scored results, let’s put them in a confusion matrix: rxCube( ~ Label : PredictedLabel , data = nnet_score, returnDataFrame = TRUE) -&gt; nnet_scores_df nnet_scores_df %&gt;% tbl_df %&gt;% group_by(Label) %&gt;% mutate(rate = Counts/sum(Counts)) %&gt;% mutate(error_rate = ifelse(Label == PredictedLabel, 0, rate)) %&gt;% ggplot(aes(x = Label, y = PredictedLabel, fill = error_rate)) + geom_raster() + scale_fill_continuous(low = &quot;steelblue2&quot;, high = &quot;mediumblue&quot;, labels = scales::percent) Just judging from the label it looks we have already done better than the linear classifier. 5.1 LeNet-5 Convolutional neural networks were popularized by Yann LeCun. In this section, we’ll fit his model from 1998, effectionately called LeNet-5. The network differs from the previous implementation in that there are now more layers, but in between layers there is a pooling/sampling layer. This helps preventing the neural network from overfitting in between layers and allows for extracting higher-order representations from the data. Because this neural network has significantly more weights to learn, it’ll take a while longer, especially if we aren’t using GPUs (which would give us at least 5-7x speed improvement). If you’re especially impatient, you can lower the numIterations parameter. rxNeuralNetFile &lt;- file.path(&quot;nnet/LeCun5.nn&quot;) lecun &lt;- readChar(rxNeuralNetFile, file.info(rxNeuralNetFile)$size) system.time(lenet_fit &lt;- rxNeuralNet(make_form(splits$train, resp_var = &quot;Label&quot;, vars_to_skip = c(&quot;splitVar&quot;)), data = splits$train, type = &quot;multiClass&quot;, numIterations = 9, netDefinition = lecun, initWtsDiameter = 1.0, normalize = &quot;No&quot;)) ## Not adding a normalizer. ## Using: SSE Math ## Loading net from: ## ***** Net definition ***** ## const T = true; ## const F = false; ## input Picture [28, 28]; ## hidden Convolve1 [6, 28, 28] from Picture convolve { ## Padding = T; ## InputShape = [28, 28]; ## KernelShape = [5, 5]; ## MapCount = 6; ## } ## hidden Subsample2 [6, 14, 14] linear from Convolve1 convolve { ## InputShape = [6, 28, 28]; ## KernelShape = [1, 2, 2]; ## Stride = [1, 2, 2]; ## Sharing = [F, T, T]; ## } ## hidden Convolve3 [16, 10, 10] from Subsample2 convolve { ## InputShape = [6, 14, 14]; ## KernelShape = [6, 5, 5]; ## MapCount = 16; ## } ## hidden Subsample4 [16, 5, 5] linear from Convolve3 convolve { ## InputShape = [16, 10, 10]; ## KernelShape = [1, 2, 2]; ## Stride = [1, 2, 2]; ## Sharing = [F, T, T]; ## } ## hidden Convolve5 [120] from Subsample4 convolve { ## InputShape = [16, 5, 5]; ## KernelShape = [16, 5, 5]; ## MapCount = 120; ## } ## hidden Full6 [84] from Convolve5 all; ## output Result [10] softmax from Full6 all; ## ***** Reduced ***** ## const T = true; ## const F = false; ## input Picture [28, 28]; ## hidden Convolve1 [6, 28, 28] from Picture convolve { ## Padding = true; ## InputShape = [28, 28]; ## KernelShape = [5, 5]; ## MapCount = 6; ## } ## hidden Subsample2 [6, 14, 14] linear from Convolve1 convolve { ## InputShape = [6, 28, 28]; ## KernelShape = [1, 2, 2]; ## Stride = [1, 2, 2]; ## Sharing = [false, true, true]; ## } ## hidden Convolve3 [16, 10, 10] from Subsample2 convolve { ## InputShape = [6, 14, 14]; ## KernelShape = [6, 5, 5]; ## MapCount = 16; ## } ## hidden Subsample4 [16, 5, 5] linear from Convolve3 convolve { ## InputShape = [16, 10, 10]; ## KernelShape = [1, 2, 2]; ## Stride = [1, 2, 2]; ## Sharing = [false, true, true]; ## } ## hidden Convolve5 120 from Subsample4 convolve { ## InputShape = [16, 5, 5]; ## KernelShape = [16, 5, 5]; ## MapCount = 120; ## } ## hidden Full6 84 from Convolve5 all; ## output Result 10 softmax from Full6 all; ## ***** End net definition ***** ## Input count: 784 ## Output count: 10 ## Output Function: SoftMax ## Loss Function: CrossEntropy ## PreTrainer: NoPreTrainer ## ___________________________________________________________________ ## Starting training... ## Learning rate: 0.001000 ## Momentum: 0.000000 ## InitWtsDiameter: 1.000000 ## ___________________________________________________________________ ## Initializing 6 Hidden Layers, 61816 Weights... ## Estimated Pre-training MeanError = 4.016721 ## Iter:1/9, MeanErr=1.566115(-61.01%), 80.01M WeightUpdates/sec ## Iter:2/9, MeanErr=0.508592(-67.53%), 80.71M WeightUpdates/sec ## Iter:3/9, MeanErr=0.350416(-31.10%), 80.86M WeightUpdates/sec ## Iter:4/9, MeanErr=0.274144(-21.77%), 81.07M WeightUpdates/sec ## Iter:5/9, MeanErr=0.231398(-15.59%), 81.38M WeightUpdates/sec ## Iter:6/9, MeanErr=0.200124(-13.52%), 81.60M WeightUpdates/sec ## Iter:7/9, MeanErr=0.180827(-9.64%), 81.64M WeightUpdates/sec ## Iter:8/9, MeanErr=0.165253(-8.61%), 81.35M WeightUpdates/sec ## Iter:9/9, MeanErr=0.154163(-6.71%), 81.24M WeightUpdates/sec ## Done! ## Estimated Post-training MeanError = 0.140622 ## ___________________________________________________________________ ## Not training a calibrator because it is not needed. ## Elapsed time: 00:07:30.0053335 ## user system elapsed ## 0.040 0.000 450.133 As before, let’s score our pretty model: lescores &lt;- rxPredict(modelObject = lenet_fit, data = splits$test, outData = tempfile(fileext = &quot;.xdf&quot;), overwrite = TRUE, extraVarsToWrite = &quot;Label&quot;) ## Elapsed time: 00:00:03.7402924 and visualize our error rates: rxCube( ~ Label : PredictedLabel , data = lescores, returnDataFrame = TRUE) -&gt; le_scores_df le_scores_df %&gt;% tbl_df %&gt;% group_by(Label) %&gt;% mutate(rate = Counts/sum(Counts)) %&gt;% mutate(error_rate = ifelse(Label == PredictedLabel, 0, rate)) %&gt;% ggplot(aes(x = Label, y = PredictedLabel, fill = error_rate)) + geom_raster() + scale_fill_continuous(low = &quot;steelblue2&quot;, high = &quot;mediumblue&quot;, labels = scales::percent) Looks even better! 5.2 Model Metrics While our visualizations provide some insight into our model’s improvement, let’s try to calculate empricial metrics of our models’ performacne. The three metrics we’ll focus on are “accuracy”, “precision”, and “recall”. Accuracy simply measures how many of our estimates we classified correctly. While simple and intuitive, it does not account for class-imbalances. For example, if 99% of our data is in class A, and we simply use the rule that everything is class A, we’ll get an accuracy of 99%. Sounds impressive, but probably not going to win any Turing tests. 5.2.1 Accuracy To calculate accuracy, we can simply measure the sum of our confusion matrix’s diagonal over all values. Our data was in a long format to make it amenable for visualizations using ggplot2. Here we’ll use tidyr to put it into a wide format amenable for calculating model metrics quickly and efficiently. calc_accuracy &lt;- function(scores_df) { library(tidyr) scores_df &lt;- as.data.frame(scores_df) scores_conf &lt;- scores_df %&gt;% spread(PredictedLabel, Counts) scores_conf &lt;- as.matrix(scores_conf[, 2:ncol(scores_conf)]) sum(diag(scores_conf))/sum(scores_conf) } sprintf(&quot;Accuracy of the softmax model is %s&quot;, calc_accuracy(softmax_scores_df)) ## [1] &quot;Accuracy of the softmax model is 0.927&quot; sprintf(&quot;Accuracy of the convolutional model is %s&quot;, calc_accuracy(nnet_scores_df)) ## [1] &quot;Accuracy of the convolutional model is 0.9628&quot; sprintf(&quot;Accuracy of the LeCun-5 model is %s&quot;, calc_accuracy(le_scores_df)) ## [1] &quot;Accuracy of the LeCun-5 model is 0.977&quot; 5.2.2 Precision Precision is another measure of model performance. It calculates the ratio of true positives to all values, i.e., how precise your model is in classifying any digit. To calculate precision, we’ll take the diagonal of our confusion matrix over the sum of that column. calc_precision &lt;- function(scores_df) { library(tidyr) scores_df &lt;- as.data.frame(scores_df) scores_conf &lt;- scores_df %&gt;% spread(PredictedLabel, Counts) scores_conf &lt;- as.matrix(scores_conf[, 2:ncol(scores_conf)]) diag(scores_conf)/colSums(scores_conf) } calc_precision(softmax_scores_df) ## 0 1 2 3 4 5 6 ## 0.9513406 0.9636049 0.9375629 0.9065880 0.9311044 0.9013921 0.9421488 ## 7 8 9 ## 0.9332024 0.8810976 0.9128713 5.2.3 Recall Lastly, we can calculate recall. Recall is a measure of how relevant the predictions are for the given class, i.e., how many of the actual classes were properly predicted. In this case, we’ll sum over the predicted labels rather than the actual labels: calc_recall &lt;- function(scores_df) { library(tidyr) scores_df &lt;- as.data.frame(scores_df) scores_conf &lt;- scores_df %&gt;% spread(PredictedLabel, Counts) scores_conf &lt;- as.matrix(scores_conf[, 2:ncol(scores_conf)]) diag(scores_conf)/rowSums(scores_conf) } calc_recall(softmax_scores_df) ## 1 2 3 4 5 6 7 ## 0.9775510 0.9797357 0.9021318 0.9128713 0.9358452 0.8710762 0.9519833 ## 8 9 10 ## 0.9241245 0.8901437 0.9137760 5.2.4 Visualzing our Metrics Let’s calculate the metrics for all three of our mdoels and visualize them. results &lt;- list(softmax = softmax_scores_df, nnet = nnet_scores_df, lecun5 = le_scores_df) metrics_df &lt;- data.frame( map_df(results, calc_precision), digits = 0:9, metric = rep(&quot;precision&quot;, 10) ) %&gt;% bind_rows(data.frame( map_df(results, calc_recall), digits = 0:9, metric = rep(&quot;recall&quot;, 10)) ) ## Warning in bind_rows_(x, .id): Unequal factor levels: coercing to character ## Warning in bind_rows_(x, .id): binding character and factor vector, ## coercing into character vector ## Warning in bind_rows_(x, .id): binding character and factor vector, ## coercing into character vector metrics_df %&gt;% gather(model, metrics, -digits, -metric) %&gt;% ggplot(aes(x = factor(digits), y = metrics, fill = model)) + geom_bar(stat = &#39;identity&#39;, position = &quot;dodge&quot;) + facet_wrap(~metric) + theme_minimal() "],
["natural-language-processing.html", "Chapter 6 Natural Language Processing 6.1 Text Classification 6.2 Neural Networks 6.3 Exercises", " Chapter 6 Natural Language Processing 6.1 Text Classification Let’s take a look at using MML to estimate a model that would be very hard to do with RevoScaleR. In particular, there are virtually no functionality in RevoScaleR for handling large text data. We will use MML to transform text data into useful features that we can use in a logistic regression learner. In order to deal with the high cardinality of text data, we will use the penalized regression models in MML. 6.1.1 IMDB Data Our data is taken from the paper Learning Word Vectors for Sentiment Analysis written in 2011 by Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. The paper and data are available here: http://ai.stanford.edu/~amaas/data/sentiment/. I’ve already downloaded and converted the data into an XDF. Please see the 1-ingest-data.R script if you are interested in the ingestion process. library(MicrosoftML) library(tidyverse) library(d3wordcloud) train_xdf &lt;- RxXdfData(&quot;data/imdb-train.xdf&quot;) test_xdf &lt;- RxXdfData(&quot;data/imdb-test.xdf&quot;) 6.1.2 Feature Transformers MicrosoftML has a set of functions for feature engineering. In this example, let’s take a look at creating sparse word vectors. We’ll use the featurizeText function to convert our text data into numeric columns. In particular, we’ll ask for new columns with tri-grams after removing stopwords, punctuations, and numbers. We can do this transform directly in our modeling call, and in particular, we’ll train logistic regression models and a fast gradient boosted tree model: system.time(logit_model &lt;- rxLogisticRegression(sentiment ~ reviewTran, data = train_xdf, l1Weight = 0.05, l2Weight = 0.01, mlTransforms = list(featurizeText( vars = c(reviewTran = &quot;review&quot;), language = &quot;English&quot;, stopwordsRemover = stopwordsDefault(), wordFeatureExtractor = ngramCount(ngramLength = 3, weighting = &quot;tfidf&quot;, maxNumTerms = 1e+09), keepNumbers = FALSE, keepPunctuations = FALSE) ) ) ) ## Not adding a normalizer. ## Automatically converting column &#39;sentiment&#39; into a factor. ## LBFGS multi-threading will attempt to load dataset into memory. In case of out-of-memory issues, turn off multi-threading by setting trainThreads to 1. ## Beginning optimization ## num vars: 4308438 ## improvement criterion: Mean Improvement ## L1 regularization selected 28533 of 4308438 weights. ## Not training a calibrator because it is not needed. ## Elapsed time: 00:02:54.4185154 ## Elapsed time: 00:00:54.5115498 ## user system elapsed ## 0.188 0.120 229.921 system.time(fast_trees &lt;- rxFastTrees(sentiment ~ reviewTran, data = train_xdf, mlTransforms = list(featurizeText( vars = c(reviewTran = &quot;review&quot;), language = &quot;English&quot;, stopwordsRemover = stopwordsDefault(), wordFeatureExtractor = ngramCount(ngramLength = 3, weighting = &quot;tfidf&quot;, maxNumTerms = 1e+09), keepNumbers = FALSE, keepPunctuations = FALSE) ) ) ) ## Not adding a normalizer. ## Automatically converting column &#39;sentiment&#39; into a factor. ## Making per-feature arrays ## Changing data from row-wise to column-wise ## Processed 25000 instances ## Binning and forming Feature objects ## Reserved memory for tree learner: 304827068 bytes ## Starting to train ... ## Not training a calibrator because it is not needed. ## Elapsed time: 00:01:10.5571151 ## user system elapsed ## 0.056 0.044 70.767 Now that we have our trained model, we can do some visualizations. For example, for the elastic net, we can visualize the coefficients. logit_cof &lt;- coefficients(logit_model) coefs &lt;- data.frame(coef = logit_cof, word = names(logit_cof)) coefs &lt;- tbl_df(coefs) coefs &lt;- coefs %&gt;% filter(word != &quot;(Bias)&quot;) %&gt;% mutate(abs_value = abs(coef), sentiment = ifelse(coef &gt; 0, &quot;Positive&quot;, &quot;Negative&quot;), score = round(abs_value, 0)) %&gt;% arrange(desc(abs_value)) %&gt;% slice(1:100) library(ggplot2) library(ggrepel) coefs %&gt;% ggplot + aes(x = 1, y = 1, colour = sentiment, size = score, label = word) + geom_text_repel(segment.size = 0, force = 10) + scale_size(range = c(2, 15), guide = FALSE) + scale_y_continuous(breaks = NULL) + scale_x_continuous(breaks = NULL) + labs(x = &#39;&#39;, y = &#39;&#39;) + theme_classic() + facet_wrap(~sentiment) Let’s try and makea more interactive visual. We’ll use purrr again to map our coefficients to the beautiful d3wordcloud package coefs %&gt;% split(.$sentiment) %&gt;% purrr::map( ~ d3wordcloud(.$word, .$score, tooltip = TRUE)) -&gt; d3_graphs d3_graphs[[1]] d3_graphs[[2]] 6.1.3 Testing the Logit Model In order to predict our classifer on test data, we will use the mxPredict function from the MML package. predictions &lt;- rxPredict(logit_model, data = test_xdf, extraVarsToWrite = &quot;sentiment&quot;) ## Elapsed time: 00:00:25.9695782 roc_results &lt;- rxRoc(actualVarName = &quot;sentiment&quot;, predVarNames = &quot;Probability.1&quot;, data = predictions) roc_results$predVarName &lt;- factor(roc_results$predVarName) plot(roc_results) 6.1.4 Testing the Fast Trees Model predictions &lt;- rxPredict(fast_trees, data = test_xdf, extraVarsToWrite = &quot;sentiment&quot;) ## Elapsed time: 00:00:29.8938884 roc_results &lt;- rxRoc(actualVarName = &quot;sentiment&quot;, predVarNames = &quot;Probability.1&quot;, data = predictions) roc_results$predVarName &lt;- factor(roc_results$predVarName) plot(roc_results) 6.2 Neural Networks Let’s try to estimate another binary classifier from this dataset, but with a Neural Network architecture rather than a logistic regression model. In the following chunk, we call our neural network model, and set the optimizer to be a stochastic gradient descent optimizer with a learning rate of 0.2. Furthermore, we use the type argument to ensure we are learning a binary classifier. By default our network architecture will have 100 hidden nodes. nn_sentiment &lt;- rxNeuralNet(sentiment ~ reviewTran, data = train_xdf, type = &quot;binary&quot;, mlTransforms = list(featurizeText(vars = c(reviewTran = &quot;review&quot;), language = &quot;English&quot;, stopwordsRemover = stopwordsDefault(), keepPunctuations = FALSE)), # acceleration = &quot;gpu&quot;, miniBatchSize = 4) ## Not adding a normalizer. ## Automatically converting column &#39;sentiment&#39; into a factor. ## Using: SSE Math ## Warning: Math acceleration mode not compatible with mini-batches. Setting batch size to 1. ## ***** Net definition ***** ## input Data [74398]; ## hidden H [100] sigmoid { // Depth 1 ## from Data all; ## } ## output Result [1] sigmoid { // Depth 0 ## from H all; ## } ## ***** End net definition ***** ## Input count: 74398 ## Output count: 1 ## Output Function: Sigmoid ## Loss Function: CrossEntropy ## PreTrainer: NoPreTrainer ## ___________________________________________________________________ ## Starting training... ## Learning rate: 0.001000 ## Momentum: 0.000000 ## InitWtsDiameter: 0.100000 ## ___________________________________________________________________ ## Initializing 1 Hidden Layers, 7440001 Weights... ## Estimated Pre-training MeanError = 0.704585 ## Iter:1/100, MeanErr=0.694443(-1.44%), 123281.76M WeightUpdates/sec ## Iter:2/100, MeanErr=0.694329(-0.02%), 125708.18M WeightUpdates/sec ## Iter:3/100, MeanErr=0.694192(-0.02%), 126223.11M WeightUpdates/sec ## Iter:4/100, MeanErr=0.694030(-0.02%), 122886.14M WeightUpdates/sec ## Iter:5/100, MeanErr=0.694215(0.03%), 122435.11M WeightUpdates/sec ## Iter:6/100, MeanErr=0.693894(-0.05%), 124689.77M WeightUpdates/sec ## Iter:7/100, MeanErr=0.693471(-0.06%), 124035.94M WeightUpdates/sec ## Iter:8/100, MeanErr=0.692859(-0.09%), 122583.35M WeightUpdates/sec ## Iter:9/100, MeanErr=0.692376(-0.07%), 124059.98M WeightUpdates/sec ## Iter:10/100, MeanErr=0.691277(-0.16%), 125373.62M WeightUpdates/sec ## Iter:11/100, MeanErr=0.690757(-0.08%), 121531.60M WeightUpdates/sec ## Iter:12/100, MeanErr=0.689446(-0.19%), 124433.26M WeightUpdates/sec ## Iter:13/100, MeanErr=0.687619(-0.26%), 126394.10M WeightUpdates/sec ## Iter:14/100, MeanErr=0.685640(-0.29%), 122750.60M WeightUpdates/sec ## Iter:15/100, MeanErr=0.683191(-0.36%), 124343.16M WeightUpdates/sec ## Iter:16/100, MeanErr=0.680226(-0.43%), 125794.01M WeightUpdates/sec ## Iter:17/100, MeanErr=0.676299(-0.58%), 122731.56M WeightUpdates/sec ## Iter:18/100, MeanErr=0.671884(-0.65%), 123546.53M WeightUpdates/sec ## Iter:19/100, MeanErr=0.666806(-0.76%), 123488.72M WeightUpdates/sec ## Iter:20/100, MeanErr=0.660784(-0.90%), 124040.20M WeightUpdates/sec ## Iter:21/100, MeanErr=0.653908(-1.04%), 120503.42M WeightUpdates/sec ## Iter:22/100, MeanErr=0.645968(-1.21%), 126882.57M WeightUpdates/sec ## Iter:23/100, MeanErr=0.637465(-1.32%), 135168.28M WeightUpdates/sec ## Iter:24/100, MeanErr=0.628361(-1.43%), 131442.95M WeightUpdates/sec ## Iter:25/100, MeanErr=0.618374(-1.59%), 132633.83M WeightUpdates/sec ## Iter:26/100, MeanErr=0.607630(-1.74%), 134216.83M WeightUpdates/sec ## Iter:27/100, MeanErr=0.596812(-1.78%), 125134.96M WeightUpdates/sec ## Iter:28/100, MeanErr=0.585189(-1.95%), 120578.85M WeightUpdates/sec ## Iter:29/100, MeanErr=0.573419(-2.01%), 122527.99M WeightUpdates/sec ## Iter:30/100, MeanErr=0.561505(-2.08%), 132514.50M WeightUpdates/sec ## Iter:31/100, MeanErr=0.549777(-2.09%), 120517.41M WeightUpdates/sec ## Iter:32/100, MeanErr=0.538191(-2.11%), 123541.32M WeightUpdates/sec ## Iter:33/100, MeanErr=0.526569(-2.16%), 126636.69M WeightUpdates/sec ## Iter:34/100, MeanErr=0.515547(-2.09%), 124143.43M WeightUpdates/sec ## Iter:35/100, MeanErr=0.504761(-2.09%), 123055.91M WeightUpdates/sec ## Iter:36/100, MeanErr=0.494128(-2.11%), 123197.09M WeightUpdates/sec ## Iter:37/100, MeanErr=0.484511(-1.95%), 125135.73M WeightUpdates/sec ## Iter:38/100, MeanErr=0.474862(-1.99%), 122756.15M WeightUpdates/sec ## Iter:39/100, MeanErr=0.465674(-1.93%), 122876.37M WeightUpdates/sec ## Iter:40/100, MeanErr=0.456896(-1.88%), 124783.00M WeightUpdates/sec ## Iter:41/100, MeanErr=0.448901(-1.75%), 121760.39M WeightUpdates/sec ## Iter:42/100, MeanErr=0.441171(-1.72%), 122997.06M WeightUpdates/sec ## Iter:43/100, MeanErr=0.433480(-1.74%), 123051.94M WeightUpdates/sec ## Iter:44/100, MeanErr=0.426293(-1.66%), 123078.74M WeightUpdates/sec ## Iter:45/100, MeanErr=0.419575(-1.58%), 121552.74M WeightUpdates/sec ## Iter:46/100, MeanErr=0.413401(-1.47%), 121503.90M WeightUpdates/sec ## Iter:47/100, MeanErr=0.406957(-1.56%), 123305.25M WeightUpdates/sec ## Iter:48/100, MeanErr=0.401313(-1.39%), 122880.33M WeightUpdates/sec ## Iter:49/100, MeanErr=0.395543(-1.44%), 123718.70M WeightUpdates/sec ## Iter:50/100, MeanErr=0.390251(-1.34%), 124812.16M WeightUpdates/sec ## Iter:51/100, MeanErr=0.385156(-1.31%), 120727.29M WeightUpdates/sec ## Iter:52/100, MeanErr=0.380155(-1.30%), 124529.75M WeightUpdates/sec ## Iter:53/100, MeanErr=0.375252(-1.29%), 120880.86M WeightUpdates/sec ## Iter:54/100, MeanErr=0.371025(-1.13%), 123749.92M WeightUpdates/sec ## Iter:55/100, MeanErr=0.366597(-1.19%), 124759.17M WeightUpdates/sec ## Iter:56/100, MeanErr=0.362269(-1.18%), 124623.17M WeightUpdates/sec ## Iter:57/100, MeanErr=0.358292(-1.10%), 122364.78M WeightUpdates/sec ## Iter:58/100, MeanErr=0.354345(-1.10%), 123185.02M WeightUpdates/sec ## Iter:59/100, MeanErr=0.350553(-1.07%), 124192.87M WeightUpdates/sec ## Iter:60/100, MeanErr=0.346730(-1.09%), 124668.77M WeightUpdates/sec ## Iter:61/100, MeanErr=0.343272(-1.00%), 118709.90M WeightUpdates/sec ## Iter:62/100, MeanErr=0.339770(-1.02%), 122861.13M WeightUpdates/sec ## Iter:63/100, MeanErr=0.336230(-1.04%), 124964.10M WeightUpdates/sec ## Iter:64/100, MeanErr=0.333191(-0.90%), 127110.62M WeightUpdates/sec ## Iter:65/100, MeanErr=0.330051(-0.94%), 129673.59M WeightUpdates/sec ## Iter:66/100, MeanErr=0.326981(-0.93%), 125489.57M WeightUpdates/sec ## Iter:67/100, MeanErr=0.323995(-0.91%), 121677.17M WeightUpdates/sec ## Iter:68/100, MeanErr=0.321182(-0.87%), 125561.40M WeightUpdates/sec ## Iter:69/100, MeanErr=0.318367(-0.88%), 128463.47M WeightUpdates/sec ## Iter:70/100, MeanErr=0.315463(-0.91%), 127737.31M WeightUpdates/sec ## Iter:71/100, MeanErr=0.313039(-0.77%), 121736.55M WeightUpdates/sec ## Iter:72/100, MeanErr=0.310367(-0.85%), 124133.90M WeightUpdates/sec ## Iter:73/100, MeanErr=0.307799(-0.83%), 123346.86M WeightUpdates/sec ## Iter:74/100, MeanErr=0.305068(-0.89%), 125222.46M WeightUpdates/sec ## Iter:75/100, MeanErr=0.302958(-0.69%), 122067.92M WeightUpdates/sec ## Iter:76/100, MeanErr=0.300405(-0.84%), 130354.63M WeightUpdates/sec ## Iter:77/100, MeanErr=0.297983(-0.81%), 121103.98M WeightUpdates/sec ## Iter:78/100, MeanErr=0.295944(-0.68%), 123852.93M WeightUpdates/sec ## Iter:79/100, MeanErr=0.293907(-0.69%), 129011.84M WeightUpdates/sec ## Iter:80/100, MeanErr=0.291620(-0.78%), 131935.73M WeightUpdates/sec ## Iter:81/100, MeanErr=0.289745(-0.64%), 123613.06M WeightUpdates/sec ## Iter:82/100, MeanErr=0.287662(-0.72%), 128522.67M WeightUpdates/sec ## Iter:83/100, MeanErr=0.285591(-0.72%), 121631.79M WeightUpdates/sec ## Iter:84/100, MeanErr=0.283583(-0.70%), 123042.63M WeightUpdates/sec ## Iter:85/100, MeanErr=0.281815(-0.62%), 128366.97M WeightUpdates/sec ## Iter:86/100, MeanErr=0.279837(-0.70%), 129162.80M WeightUpdates/sec ## Iter:87/100, MeanErr=0.278120(-0.61%), 127484.00M WeightUpdates/sec ## Iter:88/100, MeanErr=0.276277(-0.66%), 127757.02M WeightUpdates/sec ## Iter:89/100, MeanErr=0.274533(-0.63%), 129199.10M WeightUpdates/sec ## Iter:90/100, MeanErr=0.272938(-0.58%), 126966.61M WeightUpdates/sec ## Iter:91/100, MeanErr=0.270917(-0.74%), 127917.72M WeightUpdates/sec ## Iter:92/100, MeanErr=0.269519(-0.52%), 123309.13M WeightUpdates/sec ## Iter:93/100, MeanErr=0.267711(-0.67%), 127397.42M WeightUpdates/sec ## Iter:94/100, MeanErr=0.266137(-0.59%), 128667.11M WeightUpdates/sec ## Iter:95/100, MeanErr=0.264770(-0.51%), 122467.54M WeightUpdates/sec ## Iter:96/100, MeanErr=0.262845(-0.73%), 120989.12M WeightUpdates/sec ## Iter:97/100, MeanErr=0.261513(-0.51%), 122038.13M WeightUpdates/sec ## Iter:98/100, MeanErr=0.259934(-0.60%), 123533.81M WeightUpdates/sec ## Iter:99/100, MeanErr=0.258394(-0.59%), 121401.90M WeightUpdates/sec ## Iter:100/100, MeanErr=0.257150(-0.48%), 125299.77M WeightUpdates/sec ## Done! ## Estimated Post-training MeanError = 0.256146 ## ___________________________________________________________________ ## Not training a calibrator because it is not needed. ## Elapsed time: 00:02:39.1847866 6.2.1 Scoring the Neural Net We can similary score our results from the neural network model predictions &lt;- rxPredict(nn_sentiment, data = test_xdf, extraVarsToWrite = &quot;sentiment&quot;) ## Elapsed time: 00:00:13.5690285 roc_results &lt;- rxRoc(actualVarName = &quot;sentiment&quot;, predVarNames = &quot;Probability.1&quot;, data = predictions) roc_results$predVarName &lt;- factor(roc_results$predVarName) plot(roc_results) 6.3 Exercises The Rscript Rscripts/9-Other-Sentiment-Datasets.R has two additional datasets with reviews and ratings (binarized). Try the above analysis on the other two datasets. "],
["transfer-learning-with-pre-trained-deep-neural-network-architectures-the-shallow-end-of-deep-learning.html", "Chapter 7 Transfer Learning with Pre-Trained Deep Neural Network Architectures – The Shallow End of Deep Learning 7.1 Pre-Trained Models 7.2 CMU Faces Dataset 7.3 On-the Fly Featurization 7.4 Retaining Features", " Chapter 7 Transfer Learning with Pre-Trained Deep Neural Network Architectures – The Shallow End of Deep Learning 7.1 Pre-Trained Models Transfer learning is a pretty incredible method for learning expressive models without having to train a deep architecture from scratch. In some ways, it’s nearly a “free-lunch”: take a pre-built model trained for weeks on a large image corpus, and reuse the features from that model for your domain-specific task. MicrosoftML ships with a number of pre-trained DNNs on the ImageNet challenge dataset. AlexNetFeatures &lt;- read.csv(system.file( &quot;extdata/ImageAnalyticsTestData/featurizeImage_alexnet_output.csv&quot;, package = &quot;MicrosoftML&quot;), header = FALSE) ResNet18Features &lt;- read.csv(system.file( &quot;extdata/ImageAnalyticsTestData/featurizeImage_resnet18_output.csv&quot;, package = &quot;MicrosoftML&quot;), header = FALSE) ResNet50Features &lt;- read.csv(system.file( &quot;extdata/ImageAnalyticsTestData/featurizeImage_resnet50_output.csv&quot;, package = &quot;MicrosoftML&quot;), header = FALSE) ResNet101Features &lt;- read.csv(system.file( &quot;extdata/ImageAnalyticsTestData/featurizeImage_resnet101_output.csv&quot;, package = &quot;MicrosoftML&quot;), header = FALSE) lapply(list(AlexNetFeatures, ResNet18Features, ResNet50Features, ResNet101Features), dim) ## [[1]] ## [1] 2 4097 ## ## [[2]] ## [1] 2 513 ## ## [[3]] ## [1] 2 2049 ## ## [[4]] ## [1] 2 2049 7.2 CMU Faces Dataset For this notebook, we’ll use the CMU Faces dataset compiled by Tom Mitchell and his students way back in 1999. # get paths to full-resolution images, regex&quot;[[:alpha:]_]+.pgm&quot; # see: http://archive.ics.uci.edu/ml/machine-learning-databases/faces-mld/faces.data.html for image resolution info # prepare training and testing data, extract labels: left VS right l &lt;- &quot;left&quot; r &lt;- &quot;right&quot; imgs_l &lt;- list.files(&quot;data/faces&quot;, pattern = paste0(l, &quot;[[:alpha:]_]+.pgm&quot;), recursive = TRUE, full.names = TRUE) imgs_r &lt;- list.files(&quot;data/faces&quot;, pattern = paste0(r, &quot;[[:alpha:]_]+.pgm&quot;), recursive = TRUE, full.names = TRUE) l_l &lt;- length(imgs_l) l_r &lt;- length(imgs_r) train_l_l &lt;- ceiling(l_l / 2) #get balanced train and test set, split each class by half train_l_r &lt;- ceiling(l_r / 2) trainIndex_l &lt;- sample(l_l, train_l_l) trainIndex_r &lt;- sample(l_r, train_l_r) train_df &lt;- data.frame(Path = c(imgs_l[trainIndex_l], imgs_r[trainIndex_r]), Label = c(rep(TRUE, train_l_l), rep(FALSE, train_l_r)), stringsAsFactors = FALSE) test_df &lt;- data.frame(Path = c(imgs_l[-trainIndex_l], imgs_r[-trainIndex_r]), Label = c(rep(TRUE, l_l-train_l_l), rep(FALSE, l_r-train_l_r)), stringsAsFactors = FALSE) train_df &lt;- train_df[sample(nrow(train_df)),] test_df &lt;- test_df[sample(nrow(test_df)),] lapply(list(train_df, test_df), dim) ## [[1]] ## [1] 157 2 ## ## [[2]] ## [1] 155 2 7.3 On-the Fly Featurization We can develop features on-the-fly and embed them into any of the MicrosoftML learners. This is especially useful if we want to train on data that is too large to fit in memory, so instead we work in batches. mlTransform &lt;- list(loadImage(vars = list(Image = &quot;Path&quot;)), resizeImage(vars = &quot;Image&quot;, width = 224, height = 224, resizingOption = &quot;IsoPad&quot;), extractPixels(vars = list(Pixels = &quot;Image&quot;)), featurizeImage(var = &quot;Pixels&quot;, outVar = &quot;Feature&quot;, dnnModel = &quot;resnet101&quot;)) model &lt;- rxLogisticRegression(Label ~ Feature, data = train_df, mlTransforms = mlTransform, mlTransformVars = &quot;Path&quot;) ## Automatically adding a MinMax normalization transform, use &#39;norm=Warn&#39; or &#39;norm=No&#39; to turn this behavior off. ## LBFGS multi-threading will attempt to load dataset into memory. In case of out-of-memory issues, turn off multi-threading by setting trainThreads to 1. ## Warning: Too few instances to use 32 threads, decreasing to 1 thread(s) ## Beginning optimization ## num vars: 2049 ## improvement criterion: Mean Improvement ## L1 regularization selected 144 of 2049 weights. ## Not training a calibrator because it is not needed. ## Elapsed time: 00:04:18.1299345 ## Elapsed time: 00:00:00.0076987 summary(model) ## Call: ## rxLogisticRegression(formula = Label ~ Feature, data = train_df, ## mlTransforms = mlTransform, mlTransformVars = &quot;Path&quot;) ## ## LogisticRegression (BinaryClassifierTrainer) for: Label~Feature ## Data: train_df ## ## ## First 20 of 144 Non-zero Coefficients: ## (Bias): 0.2561404 ## f765: 0.9757374 ## f1789: -0.8494654 ## f1752: -0.7844995 ## f396: 0.6964862 ## f1837: -0.6718948 ## f1496: -0.614819 ## f1173: 0.614722 ## f530: -0.6073583 ## f78: 0.5863273 ## f851: 0.5443665 ## f39: -0.5386707 ## f1961: -0.5299587 ## f1409: -0.4981045 ## f529: 0.4914077 ## f573: 0.4909203 ## f619: -0.4871628 ## f2011: 0.4459811 ## f779: -0.4267508 ## f596: 0.4123578 score &lt;- rxPredict(model, test_df, extraVarsToWrite = &quot;Label&quot;) ## Elapsed time: 00:04:20.7192206 sum(score$Label==score$PredictedLabel)/nrow(score) ## [1] 0.9612903 rxRocCurve(&quot;Label&quot;,&quot;Probability&quot;, score) 7.4 Retaining Features While the above approach is scalable beyond datasets that can fit in memory, it has the drawback of not being reusable. In paricular, we can’t “pull-out” the features we trained on our dataset for later use. If you would like to retain the features you trained on, you can do so by using the featurizeImage function in MicrosoftML directly. It is analogous to the mlTransforms argumenet above. rxFeaturize(data = train_df, outData = &quot;data/train.xdf&quot;, overwrite = TRUE, mlTransforms = list(loadImage(vars = list(Image = &quot;Path&quot;)), resizeImage(vars = &quot;Image&quot;, width = 224, height = 224, resizingOption = &quot;IsoPad&quot;), extractPixels(vars = list(Pixels = &quot;Image&quot;)), featurizeImage(var = &quot;Pixels&quot;, outVar = &quot;Feature&quot;, dnnModel = &quot;resnet18&quot;)), mlTransformVars = c(&quot;Path&quot;, &quot;Label&quot;)) -&gt; train_xdf ## Elapsed time: 00:00:22.4899601 rxFeaturize(data = test_df, outData = &quot;data/test.xdf&quot;, overwrite = TRUE, mlTransforms = list(loadImage(vars = list(Image = &quot;Path&quot;)), resizeImage(vars = &quot;Image&quot;, width = 224, height = 224, resizingOption = &quot;IsoPad&quot;), extractPixels(vars = list(Pixels = &quot;Image&quot;)), featurizeImage(var = &quot;Pixels&quot;, outVar = &quot;Feature&quot;, dnnModel = &quot;resnet18&quot;)), mlTransformVars = c(&quot;Path&quot;, &quot;Label&quot;)) -&gt; test_xdf ## Elapsed time: 00:00:21.9257951 varInfo &lt;- rxGetVarInfo(train_xdf) features &lt;- paste(&quot;Feature&quot;, 0:511, sep=&quot;.&quot;, collapse = &quot; + &quot;) form &lt;- as.formula(paste(&quot;Label&quot;, features, sep=&quot;~&quot;)) model &lt;- rxLogisticRegression(formula = form, data = train_xdf) ## Automatically adding a MinMax normalization transform, use &#39;norm=Warn&#39; or &#39;norm=No&#39; to turn this behavior off. ## LBFGS multi-threading will attempt to load dataset into memory. In case of out-of-memory issues, turn off multi-threading by setting trainThreads to 1. ## Warning: Too few instances to use 32 threads, decreasing to 1 thread(s) ## Beginning optimization ## num vars: 513 ## improvement criterion: Mean Improvement ## L1 regularization selected 97 of 513 weights. ## Not training a calibrator because it is not needed. ## Elapsed time: 00:00:00.6764841 ## Elapsed time: 00:00:00.0022477 summary(model) ## Call: ## rxLogisticRegression(formula = form, data = train_xdf) ## ## LogisticRegression (BinaryClassifierTrainer) for: Label~Feature.0+Feature.1+Feature.2+Feature.3+Feature.4+Feature.5+Feature.6+Feature.7+Feature.8+Feature.9+Feature.10+Feature.11+Feature.12+Feature.13+Feature.14+Feature.15+Feature.16+Feature.17+Feature.18+Feature.19+Feature.20+Feature.21+Feature.22+Feature.23+Feature.24+Feature.25+Feature.26+Feature.27+Feature.28+Feature.29+Feature.30+Feature.31+Feature.32+Feature.33+Feature.34+Feature.35+Feature.36+Feature.37+Feature.38+Feature.39+Feature.40+Feature.41+Feature.42+Feature.43+Feature.44+Feature.45+Feature.46+Feature.47+Feature.48+Feature.49+Feature.50+Feature.51+Feature.52+Feature.53+Feature.54+Feature.55+Feature.56+Feature.57+Feature.58+Feature.59+Feature.60+Feature.61+Feature.62+Feature.63+Feature.64+Feature.65+Feature.66+Feature.67+Feature.68+Feature.69+Feature.70+Feature.71+Feature.72+Feature.73+Feature.74+Feature.75+Feature.76+Feature.77+Feature.78+Feature.79+Feature.80+Feature.81+Feature.82+Feature.83+Feature.84+Feature.85+Feature.86+Feature.87+Feature.88+Feature.89+Feature.90+Feature.91+Feature.92+Feature.93+Feature.94+Feature.95+Feature.96+Feature.97+Feature.98+Feature.99+Feature.100+Feature.101+Feature.102+Feature.103+Feature.104+Feature.105+Feature.106+Feature.107+Feature.108+Feature.109+Feature.110+Feature.111+Feature.112+Feature.113+Feature.114+Feature.115+Feature.116+Feature.117+Feature.118+Feature.119+Feature.120+Feature.121+Feature.122+Feature.123+Feature.124+Feature.125+Feature.126+Feature.127+Feature.128+Feature.129+Feature.130+Feature.131+Feature.132+Feature.133+Feature.134+Feature.135+Feature.136+Feature.137+Feature.138+Feature.139+Feature.140+Feature.141+Feature.142+Feature.143+Feature.144+Feature.145+Feature.146+Feature.147+Feature.148+Feature.149+Feature.150+Feature.151+Feature.152+Feature.153+Feature.154+Feature.155+Feature.156+Feature.157+Feature.158+Feature.159+Feature.160+Feature.161+Feature.162+Feature.163+Feature.164+Feature.165+Feature.166+Feature.167+Feature.168+Feature.169+Feature.170+Feature.171+Feature.172+Feature.173+Feature.174+Feature.175+Feature.176+Feature.177+Feature.178+Feature.179+Feature.180+Feature.181+Feature.182+Feature.183+Feature.184+Feature.185+Feature.186+Feature.187+Feature.188+Feature.189+Feature.190+Feature.191+Feature.192+Feature.193+Feature.194+Feature.195+Feature.196+Feature.197+Feature.198+Feature.199+Feature.200+Feature.201+Feature.202+Feature.203+Feature.204+Feature.205+Feature.206+Feature.207+Feature.208+Feature.209+Feature.210+Feature.211+Feature.212+Feature.213+Feature.214+Feature.215+Feature.216+Feature.217+Feature.218+Feature.219+Feature.220+Feature.221+Feature.222+Feature.223+Feature.224+Feature.225+Feature.226+Feature.227+Feature.228+Feature.229+Feature.230+Feature.231+Feature.232+Feature.233+Feature.234+Feature.235+Feature.236+Feature.237+Feature.238+Feature.239+Feature.240+Feature.241+Feature.242+Feature.243+Feature.244+Feature.245+Feature.246+Feature.247+Feature.248+Feature.249+Feature.250+Feature.251+Feature.252+Feature.253+Feature.254+Feature.255+Feature.256+Feature.257+Feature.258+Feature.259+Feature.260+Feature.261+Feature.262+Feature.263+Feature.264+Feature.265+Feature.266+Feature.267+Feature.268+Feature.269+Feature.270+Feature.271+Feature.272+Feature.273+Feature.274+Feature.275+Feature.276+Feature.277+Feature.278+Feature.279+Feature.280+Feature.281+Feature.282+Feature.283+Feature.284+Feature.285+Feature.286+Feature.287+Feature.288+Feature.289+Feature.290+Feature.291+Feature.292+Feature.293+Feature.294+Feature.295+Feature.296+Feature.297+Feature.298+Feature.299+Feature.300+Feature.301+Feature.302+Feature.303+Feature.304+Feature.305+Feature.306+Feature.307+Feature.308+Feature.309+Feature.310+Feature.311+Feature.312+Feature.313+Feature.314+Feature.315+Feature.316+Feature.317+Feature.318+Feature.319+Feature.320+Feature.321+Feature.322+Feature.323+Feature.324+Feature.325+Feature.326+Feature.327+Feature.328+Feature.329+Feature.330+Feature.331+Feature.332+Feature.333+Feature.334+Feature.335+Feature.336+Feature.337+Feature.338+Feature.339+Feature.340+Feature.341+Feature.342+Feature.343+Feature.344+Feature.345+Feature.346+Feature.347+Feature.348+Feature.349+Feature.350+Feature.351+Feature.352+Feature.353+Feature.354+Feature.355+Feature.356+Feature.357+Feature.358+Feature.359+Feature.360+Feature.361+Feature.362+Feature.363+Feature.364+Feature.365+Feature.366+Feature.367+Feature.368+Feature.369+Feature.370+Feature.371+Feature.372+Feature.373+Feature.374+Feature.375+Feature.376+Feature.377+Feature.378+Feature.379+Feature.380+Feature.381+Feature.382+Feature.383+Feature.384+Feature.385+Feature.386+Feature.387+Feature.388+Feature.389+Feature.390+Feature.391+Feature.392+Feature.393+Feature.394+Feature.395+Feature.396+Feature.397+Feature.398+Feature.399+Feature.400+Feature.401+Feature.402+Feature.403+Feature.404+Feature.405+Feature.406+Feature.407+Feature.408+Feature.409+Feature.410+Feature.411+Feature.412+Feature.413+Feature.414+Feature.415+Feature.416+Feature.417+Feature.418+Feature.419+Feature.420+Feature.421+Feature.422+Feature.423+Feature.424+Feature.425+Feature.426+Feature.427+Feature.428+Feature.429+Feature.430+Feature.431+Feature.432+Feature.433+Feature.434+Feature.435+Feature.436+Feature.437+Feature.438+Feature.439+Feature.440+Feature.441+Feature.442+Feature.443+Feature.444+Feature.445+Feature.446+Feature.447+Feature.448+Feature.449+Feature.450+Feature.451+Feature.452+Feature.453+Feature.454+Feature.455+Feature.456+Feature.457+Feature.458+Feature.459+Feature.460+Feature.461+Feature.462+Feature.463+Feature.464+Feature.465+Feature.466+Feature.467+Feature.468+Feature.469+Feature.470+Feature.471+Feature.472+Feature.473+Feature.474+Feature.475+Feature.476+Feature.477+Feature.478+Feature.479+Feature.480+Feature.481+Feature.482+Feature.483+Feature.484+Feature.485+Feature.486+Feature.487+Feature.488+Feature.489+Feature.490+Feature.491+Feature.492+Feature.493+Feature.494+Feature.495+Feature.496+Feature.497+Feature.498+Feature.499+Feature.500+Feature.501+Feature.502+Feature.503+Feature.504+Feature.505+Feature.506+Feature.507+Feature.508+Feature.509+Feature.510+Feature.511 ## Data: train_xdf (RxXdfData Data Source) ## File name: data/train.xdf ## ## ## First 20 of 97 Non-zero Coefficients: ## (Bias): 0.2091156 ## Feature.487: -1.327465 ## Feature.431: 0.9092103 ## Feature.460: -0.8586729 ## Feature.157: 0.7992205 ## Feature.47: -0.7986112 ## Feature.511: -0.6897881 ## Feature.315: -0.6197985 ## Feature.270: 0.6049663 ## Feature.233: -0.5948368 ## Feature.62: 0.5754997 ## Feature.456: 0.56534 ## Feature.293: 0.5637971 ## Feature.269: -0.5151423 ## Feature.441: -0.493934 ## Feature.88: 0.483808 ## Feature.406: -0.4684003 ## Feature.93: 0.465048 ## Feature.145: -0.4564239 ## Feature.224: -0.4489715 score &lt;-rxPredict(model, test_xdf, extraVarsToWrite = &quot;Label&quot;) ## Elapsed time: 00:00:00.1704341 sum(score$Label==score$PredictedLabel)/nrow(score) ## [1] 0.9870968 rxRocCurve(&quot;Label&quot;,&quot;Probability&quot;,score) "]
]
